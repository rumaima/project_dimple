<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="DiMPLe introduces a disentangled multi-modal prompt learning method that separates invariant clinical features from spurious cues across text and image modalities for robust generalization under distribution shift.">
  <meta property="og:title" content="DiMPLe: Disentangled Multi-Modal Prompt Learning"/>
  <meta property="og:description" content="Robust adaptation under distribution shift via prompt-guided decoupling of invariant and spurious features in vision-language models."/>
  <meta property="og:url" content="https://openreview.net/forum?id=mYmg0I9jfE"/>
  <meta property="og:image" content="static/image/" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <meta name="twitter:title" content="DiMPLe: Disentangled Multi-Modal Prompt Learning">
  <meta name="twitter:description" content="Domain-robust multi-modal adaptation via disentangled prompt tuning in vision-language models">
  <meta name="twitter:image" content="static/images/dimple_twitter_banner.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="DiMPLe, multi-modal learning, OOD generalization, vision-language models, prompt tuning, disentanglement">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>DiMPLe: Disentangled Multi-Modal Prompt Learning</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">DiMPLe: Disentangled Multi-Modal Prompt Learning <br> [ICCV 2025]</h1>
          <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
                <span class="author-block">
                <a href="https://rumaima.github.io/umaimarahman.github.io/" target="_blank">Umaima Rahman</a><sup>1</sup>,</span>
                <span class="author-block">
                <a href="https://mbzuai.ac.ae/study/faculty/mohammad-yaqub/" target="_blank">Mohammad Yaqub</a><sup>1</sup>,</span>
                <span class="author-block">
                <a href="https://scholar.google.com/citations?user=j5K7HPoAAAAJ&hl=en" target="_blank">Dwarikanath Mahapatra</a><sup>2</sup>,</span>
                </span>
            </div>

            <div class="is-size-5 publication-authors">
                 <span class="author-block"><sup>1</sup>Mohamed Bin Zayed University of Artificial Intelligence</span>
                    &nbsp;
                  <span class="affliatiton"><sup>2</sup>Khalifa Univerity</span>
                  &nbsp;
                      
            </div>
          
          <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2506.21237" target="_blank"
                       class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>pdf</span>
                    </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (coming soon)</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2506.21237" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser figures section -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered">
        <div class="column is-10">
          <div class="content has-text-centered">

            <figure>
              <img src="static/images/figure_1.png" alt="Figure 1: Overview of DiMPLe">
              <figcaption class="subtitle mt-2">
                <strong>Figure 1:</strong> (a) Without the explicit mapping in previous methods, spurious elements in the text embeddings may inadvertently align with the visual modelâ€™s invariant features, weakening the model's robustness and reducing its effectiveness on novel classes and out-of-distribution images. (b) Importance of a principled method (\textbf{DiMPLe}) for disentangling multi-modal representations, to enhance generalization for novel classes as well as to improve the robustness of multi-modal models against distribution shifts for the same class by explicitly mapping the invariant and spurious features for each modality. (c) In previous methods, during training, the general textual features are used to align with the invariant image features as well as spurious image features. (d) \textbf{DiMPLe} removes the ambiguous mapping by aligning the invariant textual and image features as well as associating spurious textual features with their spurious image counterparts.
              </figcaption>
            </figure>

            <div class="content has-text-justified mt-6">
              <h3 class="title is-4">Abstract</h3>
              <p>
                We introduce <strong>DiMPLe</strong> (Disentangled Multi-Modal Prompt Learning), a novel method for separating invariant and spurious features across both vision and language modalities. DiMPLe aligns class-relevant information while filtering spurious correlations by combining conditional mutual information minimization, spurious feature regularization, and contrastive learning on invariant representations. This structured disentanglement across modalities improves generalization to novel categories and robustness under distribution shifts.
              </p>
            </div>

            <figure>
              <img src="static/images/figure_dimple_arch.png" alt="Figure 2: DiMPLe Architecture">
              <figcaption class="subtitle mt-2">
                <strong>Figure 2:</strong> An overview of DiMPLe:Disentangled Multi-modal Prompt Learning, a unified multi-modal prompt-tuning approach that leverages disentangled image and text features, along with multi-stage deep prompting where vision prompts are conditioned on language.
              </figcaption>
            </figure>

            <div class="content has-text-justified mt-6">
              <h3 class="title is-4">Key Insight</h3>
              <p>
                A crucial insight of DiMPLe is that spurious features in images often correspond to spurious components in textual prompts. Previous methods ignored this cross-modal alignment, leading to ambiguous supervision. DiMPLe explicitly aligns invariant features with invariant counterparts and similarly for spurious features, thereby enforcing coherent representations across modalities.
              </p>
            </div>

            <figure>
              <img src="static/images/figure_radar_plot.png" alt="Figure 3: Radar Plot Evaluation">
              <figcaption class="subtitle mt-2">
                <strong>Figure 3:</strong> A radar plot showing the results using CoOp-OOD, DiMPLe, DiMPLe-E for Cross-Dataset (11 datasets) and Domain-Generalization (4 ImageNet variants) evaluation. For training, all 1000 classes of ImageNet were used and the respective models were evaluated using the above datasets in a zero-shot setting.
              </figcaption>
            </figure>

            <div class="columns is-centered mt-6">
            <div class="column is-half has-text-centered">
              <img src="static/images/figure_tsne_coopood.png" alt="t-SNE of CoOp-OOD" style="max-width: 90%; height: auto;">
            </div>
            <div class="column is-half has-text-centered">
              <img src="static/images/figure_tsne_dimple.png" alt="t-SNE of DiMPLe" style="max-width: 90%; height: auto;">
            </div>
          </div>
          <div class="has-text-centered subtitle mt-4">
            <strong>Figure 4:</strong> t-SNE visualizations comparing CoOp-OOD (left) and DiMPLe (right). DiMPLe achieves clearer separation between invariant and spurious features across modalities, with more distinct class-wise clusters.
          </div>

            <div class="content has-text-justified mt-6">
              <h3 class="title is-4">Class Discrimination Ability-CoOp-OOD vs DiMPLe:</h3>
              <p>
                The ability to distinctly represent different classes in the feature space, is a crucial aspect of robust image classification, especially in scenarios involving OOD data. We use t-SNE plots to visualize embedding distribution, providing insights into class separation and cluster compactness.
                The t-SNE visualizations in Fig. \ref{fig:tsne} compare the the class discrimination capabilities of CoOp-OOD and DiMPLe, revealing notable differences between the two approaches as evident. Firstly, the compactness of clusters in DiMPLe embeddings \ref{fig:tsne} (bottom) indicates lower intra-class variance, meaning that samples from the same class are more tightly grouped. CoOp-OOD embeddings \ref{fig:tsne} (top), however, show looser clusters. Secondly, these visualizations confirm our hypothesis of the importance of segregating the invariant and spurious features for both modalities. Fig. \ref{fig:tsne} (top) presents a tSNE visualization using the CoOp-OOD method. It shows how the invariant image features (circle) are separated from spurious image features (diamond), and all the textual features (triangle) are closer to invariant image features in the embedding space compared to the spurious ones. In contrast to this \ref{fig:tsne} (bottom) presents a tSNE visualization using our approach i.e., DiMPLe. This empirically shows how the textual invariant features (star) are aligned with the image invariant features (circle) whereas the textual spurious features (triangle) which are closer to the image spurious features are well separated from the invariant ones. Thereby involving the multi-modal invariant features to effectively contribute towards the accurate prediction of a class and minimizing the influence of the spurious ones. Thus we can conclude that by explicitly disentangling invariant and spurious features across the vision-language modalities, DiMPLe ensures that invariant embeddings primarily focus on class-relevant information. 
              </p>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End teaser figures section -->

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Website template adapted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
